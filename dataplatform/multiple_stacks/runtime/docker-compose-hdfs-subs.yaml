version: "3.9"
services:
  namenode1:
    image: apache/hadoop:3.3.6
    ports:
      - 9870:9870
    volumes:
      - namenode1_data:/hadoop/dfs/name
      - namenode1_config:/opt/hadoop/etc/hadoop/
      - scripts:/scripts/
    command:
      - /bin/bash
      - -c
      - |
        sleep 20
        mkdir -p /hadoop/dfs/name
        sudo chown hadoop /hadoop/dfs/name
        if [ ! -d /hadoop/dfs/name ]; then
          echo "Namenode name directory not found: /hadoop/dfs/name"
          exit 2
        fi

        if [ -z "TEST" ]; then
          echo "Cluster name not specified"
          export CLUSTERNAME=test
        fi

        if [ "`ls -A /hadoop/dfs/name`" == "" ]; then
          echo "Formatting namenode name directory: /hadoop/dfs/name"
          /opt/hadoop/bin/hdfs --config /opt/hadoop/etc/hadoop namenode -format -y TEST
        else
          echo "/hadoop/dfs/name exists!"
        fi
        hdfs zkfc -formatZK -nonInteractive
        echo "Done formatting ZK ... starting zkfc"
        hdfs --daemon start zkfc -Ddfs.ha.namenodeid=namenode1
        echo "Started zkfc"
        hdfs --config /opt/hadoop/etc/hadoop namenode
    deploy:
      placement:
        constraints:
          - node.role == manager
    networks:
      - BIG-dataplatform-network 
    
  namenode2:
    image: apache/hadoop:3.3.6
    ports:
      - 9871:9871
    volumes:
      - namenode2_data:/hadoop/dfs/name
      - namenode2_config:/opt/hadoop/etc/hadoop/
      - scripts:/scripts/
    command:
      - /bin/bash
      - -c
      - |
        sleep 35
        mkdir -p /hadoop/dfs/name
        sudo chown hadoop /hadoop/dfs/name
        chmod +x /scripts/fencing_script.sh
        if [ "`ls -A /hadoop/dfs/name`" == "" ]; then
          echo "Bootstrappppppping namenode2"
          /opt/hadoop/bin/hdfs namenode -bootstrapStandby
        fi
        echo "starting zkfc"
        hdfs --daemon start zkfc > zkfc_logs.txt
        echo "Started zkfc"
        hdfs --config /opt/hadoop/etc/hadoop namenode
    deploy:
      placement:
        constraints:
          - node.role == manager
    networks:
      - BIG-dataplatform-network 

  journal1:
    image: apache/hadoop:3.3.6
    volumes:
      - journal1_data:/data/journalnode
      - hadoop_config:/opt/hadoop/etc/hadoop/
    command: 
      - /bin/bash
      - -c
      - |
        mkdir -p /data/journalnode
        sudo chown hadoop /data/journalnode
        hdfs journalnode
    deploy:
      placement:
        constraints:
          - node.role == manager
    networks:
      - BIG-dataplatform-network

  journal2:
    image: apache/hadoop:3.3.6
    volumes:
      - journal2_data:/data/journalnode
      - hadoop_config:/opt/hadoop/etc/hadoop/
    command:       
      - /bin/bash
      - -c
      - |
        mkdir -p /data/journalnode
        sudo chown hadoop /data/journalnode
        hdfs journalnode
    deploy:
      placement:
        constraints:
          - node.role == manager
    networks:
      - BIG-dataplatform-network 

  journal3:
    image: apache/hadoop:3.3.6
    volumes:
      - journal3_data:/data/journalnode
      - hadoop_config:/opt/hadoop/etc/hadoop/
    command:
      - /bin/bash
      - -c
      - |
        mkdir -p /data/journalnode
        sudo chown hadoop /data/journalnode
        hdfs journalnode
    deploy:
      placement:
        constraints:
          - node.role == manager
    networks:
      - BIG-dataplatform-network

  datanode:
    image: apache/hadoop:3.3.6
    volumes:
      - datanode1_data:/hadoop/dfs/data
      - hadoop_config:/opt/hadoop/etc/hadoop/
    command:
      - /bin/bash
      - -c
      - |
        sleep 30
        sudo chown hadoop /hadoop/dfs/data
        if [ ! -d /hadoop/dfs/data ]; then
          echo "Datanode data directory not found: /hadoop/dfs/data"
          exit 2
        fi
        hdfs --config /opt/hadoop/etc/hadoop datanode
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == worker
    networks:
      - BIG-dataplatform-network

volumes:
  scripts:
    driver_opts:
      type: nfs
      o: addr=137.204.74.55,rw,nfsvers=4
      device: :/mnt/mysharednfs/dataplatform/scripts/
  namenode1_config:
    driver_opts:
      type: nfs
      o: addr=137.204.74.55,rw,nfsvers=4
      device: :/mnt/mysharednfs/dataplatform/namenode1_conf/
    
  namenode1_data:
    driver_opts:
      type: nfs
      o: addr=137.204.74.55,rw,nfsvers=4
      device: :/mnt/mysharednfs/dataplatform/namenode1_data/

  namenode2_config:
    driver_opts:
      type: nfs
      o: addr=137.204.74.55,rw,nfsvers=4
      device: :/mnt/mysharednfs/dataplatform/namenode2_conf/

  namenode2_data:
    driver_opts:
      type: nfs
      o: addr=137.204.74.55,rw,nfsvers=4
      device: :/mnt/mysharednfs/dataplatform/namenode2_data/

  journal1_data:
    driver_opts:
      type: nfs
      o: addr=137.204.74.55,rw,nfsvers=4
      device: :/mnt/mysharednfs/dataplatform/journal1_data/

  journal2_data:
    driver_opts:
      type: nfs
      o: addr=137.204.74.55,rw,nfsvers=4
      device: :/mnt/mysharednfs/dataplatform/journal2_data/

  journal3_data:
    driver_opts:
      type: nfs
      o: addr=137.204.74.55,rw,nfsvers=4
      device: :/mnt/mysharednfs/dataplatform/journal3_data/

  datanode1_data:
    driver_opts:
      type: nfs
      o: addr=137.204.74.55,rw,nfsvers=4
      device: :/mnt/mysharednfs/dataplatform/datanode1_data/

  hadoop_config:
    driver: local
    driver_opts:
      type: nfs
      o: addr=137.204.74.55,rw,nfsvers=4,nolock,hard
      device: ":/mnt/mysharednfs/dataplatform/hadoop_conf/"
  
networks:
  BIG-dataplatform-network:
    external: true
    name: BIG-dataplatform-network