version: "3.9"
services:
  spark-yarn-test-env:
    image: apache/spark:${SPARKVERSION}
    environment:
      - SPARK_NO_DAEMONIZE=true
      - HADOOP_CONF_DIR=${SPARKCONFDIR}
    volumes:
      - spark_config:${SPARKCONFDIR}
      - hadoop_config:${HADOOPCONFDIR}
      - test_files:/opt/spark/tests
    command:
      - /bin/bash
      - -c
      - |
        cp -r ${HADOOPCONFDIR}* ${SPARKCONFDIR}
        tail -f /dev/null
    deploy:
      placement:
        constraints:
          - node.role == worker
    stdin_open: true 
    tty: true
    networks:
      - BIG-dataplatform-network

  portainer:
    init: true
    image: portainer/portainer-ce:latest
    ports:
      - ${PORTAINERPORT}:${PORTAINERPORT}
    volumes:
        - /var/run/docker.sock:/var/run/docker.sock
        - ./../../portainer_data:/data
    deploy:
      placement:
        constraints:
          - node.role == manager  
    networks:
      - BIG-dataplatform-network

volumes:
  spark_config:
    driver_opts:
      type: nfs
      o: addr=137.204.74.55,rw,nfsvers=4
      device: ":/mnt/mysharednfs/dataplatform/spark_conf/"
        
  hadoop_config:
    driver: local
    driver_opts:
      type: nfs
      o: addr=137.204.74.55,rw,nfsvers=4,nolock,hard
      device: ":/mnt/mysharednfs/dataplatform/hadoop_conf/"

  test_files:
    driver_opts:
      type: nfs
      o: addr=137.204.74.55,rw,nfsvers=4
      device: :/mnt/mysharednfs/dataplatform/tests/

networks:
  BIG-dataplatform-network:
    external: true
    name: BIG-dataplatform-network