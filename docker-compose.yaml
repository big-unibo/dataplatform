version: "3"
services:
   namenode1:
      image: apache/hadoop:3
      hostname: namenode1
      ports:
         - 9870:9870
      env_file:
         - ./config
      environment:
          ENSURE_NAMENODE_DIR: "/tmp/hadoop-hadoop/dfs/name"
          SLEEP_SECONDS: 20
      command: ["hdfs", "namenode"]
      volumes:
      #  - ./namenodeformat.sh:/opt/launcher/plugins/012_namenodeformat/namenodeformat.sh
         - hadoop_namenode:/hadoop/dfs/name

   namenode2:
      image: apache/hadoop:3
      hostname: namenode2
      ports:
         - 9871:9870
      env_file:
         - ./config
      environment:
          ENSURE_STANDBY_NAMENODE_DIR: "/tmp/hadoop-hadoop/dfs/name"
          SLEEP_SECONDS: 40
      command: ["hdfs", "namenode"]
      volumes:
      #   - ./namenodeformat.sh:/opt/launcher/plugins/012_namenodeformat/namenodeformat.sh
         - hadoop_namenode:/hadoop/dfs/name
         
   journal1:
      image: apache/hadoop:3
      hostname: journal1
      env_file:
        - ./config
      command: ["hdfs", "journalnode"]
     # environment:
        # SLEEP_SECONDS: 50
   journal2:
      image: apache/hadoop:3
      hostname: journal2
      env_file:
        - ./config
      command: ["hdfs", "journalnode"]
     # environment:
        # SLEEP_SECONDS: 50
   journal3:
      image: apache/hadoop:3
      hostname: journal3
      env_file:
        - ./config
      command: ["hdfs", "journalnode"]
     # environment:
       #  SLEEP_SECONDS: 50
      
   datanode:
      image: apache/hadoop:3
      command: ["hdfs", "datanode"]
      env_file:
        - ./config
      environment:
         SLEEP_SECONDS: 50

   activator:
      image: apache/hadoop:3
      command: ["hdfs", "haadmin", "-transitionToActive", "nn1"]
      env_file:
        - ./config
      environment:
         SLEEP_SECONDS: 60

   resourcemanager:
      image: apache/hadoop:3
      hostname: resourcemanager
      command: ["yarn", "resourcemanager"]
      ports:
         - 8088:8088
      env_file:
        - ./config
      volumes:
        - ./test.sh:/opt/test.sh
      environment:
         SLEEP_SECONDS: 60
        
   nodemanager:
      image: apache/hadoop:3
      command: ["yarn", "nodemanager"]
      env_file:
        - ./config
      environment:
         SLEEP_SECONDS: 60
   
   spark-master:
      image: apache/spark:v3.3.0
      container_name: spark-master
      command: 
         - "/opt/spark/sbin/start-master.sh"
      environment:
         - SPARK_NO_DAEMONIZE=true
         - SLEEP_SECONDS=60
      env_file:
         - ./spark-config
      volumes:
         - ./conf:/opt/spark/conf/
      ports:
         - ${SPARK_MASTER_PORT}:${SPARK_MASTER_PORT} 

   spark-worker:
      image: apache/spark:v3.3.0
      container_name: spark-worker
      environment:
         - SPARK_NO_DAEMONIZE=true
         - SLEEP_SECONDS=60
      command: "/opt/spark/sbin/start-worker.sh spark://${SPARK_MASTER_HOST}:${SPARK_MASTER_PORT}"
      env_file:
         - ./spark-config
      volumes:
         - ./conf:/opt/spark/conf/
      depends_on:
         - spark-master

   spark-history-server:
      image: apache/spark:v3.3.0
      container_name: spark-history-server
      environment:
         - SPARK_NO_DAEMONIZE=true
         - SLEEP_SECONDS=60
      command: "/opt/spark/sbin/start-history-server.sh"
      env_file:
         - ./spark-config
      volumes:
         - ./conf:/opt/spark/conf/
         - /tmp/spark-events-local:/tmp/spark-events
      ports:
         - ${SPARK_HISTORY_PORT}:${SPARK_HISTORY_PORT}
      depends_on:
         - spark-master
      restart: always

volumes:
  hadoop_namenode:
  hadoop_datanode: